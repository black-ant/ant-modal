# =============================================================================
# Wan 2.1 T2V (Text-to-Video) ComfyUI ä¸€é”®éƒ¨ç½²æœåŠ¡
# =============================================================================
# å¯åŠ¨å‘½ä»¤: modal deploy wan21_t2v_deploy.py
# UI ç«¯å£: 24782
# GPU: L40S (48GB) - ä½¿ç”¨ FP8 é‡åŒ–æ¨¡å‹ï¼Œæ˜¾å­˜éœ€æ±‚ä½ï¼Œè´¨é‡æ— æŸ
# =============================================================================

import json
import os
import subprocess
from pathlib import Path

import modal

# =============================================================================
# é…ç½®åŒºåŸŸ
# =============================================================================
# HuggingFace æ¨¡å‹ä»“åº“ (Wan 2.1 T2V)
WAN_MODEL_REPO = "Wan-Video/Wan2.1-T2V-14B"

# å¤‡ç”¨è½»é‡æ¨¡å‹ (1.3B ç‰ˆæœ¬ï¼Œæ˜¾å­˜éœ€æ±‚ä½)
WAN_MODEL_REPO_LITE = "Wan-Video/Wan2.1-T2V-1.3B"

# æ¨¡å‹ç²¾åº¦é…ç½®
MODEL_DTYPE = "fp8"  # fp8 é‡åŒ–ï¼Œæ˜¾å­˜éœ€æ±‚é™ä½ 50%
GPU_TYPE = "L40S"    # L40S 48GB æ˜¾å­˜è¶³å¤Ÿè¿è¡Œ FP8 æ¨¡å‹

# Volume åç§°
MODEL_VOLUME_NAME = "wan21-t2v-model-cache"

# æœåŠ¡ç«¯å£
UI_PORT = 24782

# =============================================================================
# S1: ç¯å¢ƒå‡†å¤‡ - æ„å»ºåŸºç¡€é•œåƒ
# =============================================================================
image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install(
        "git", "wget", "curl", "ffmpeg",
        "libgl1", "libglib2.0-0", "libsm6", "libxext6", "libxrender1"
    )
    .pip_install(
        "fastapi[standard]==0.115.4",
        "comfy-cli==1.5.3",
        "requests==2.32.3",
        "torch==2.5.1",
        "torchvision==0.20.1",
        "torchaudio==2.5.1",
    )
    .run_commands("comfy --skip-prompt install --fast-deps --nvidia")
    # å®‰è£… WanVideoWrapper è‡ªå®šä¹‰èŠ‚ç‚¹ (æ”¯æŒ Wan 2.x ç³»åˆ—)
    .run_commands(
        "cd /root/comfy/ComfyUI/custom_nodes && "
        "git clone https://github.com/kijai/ComfyUI-WanVideoWrapper.git"
    )
    .run_commands(
        "cd /root/comfy/ComfyUI/custom_nodes/ComfyUI-WanVideoWrapper && "
        "pip install -r requirements.txt || true"
    )
    # å®‰è£… VideoHelperSuite ç”¨äºè§†é¢‘ä¿å­˜
    .run_commands(
        "cd /root/comfy/ComfyUI/custom_nodes && "
        "git clone https://github.com/Kosinkadink/ComfyUI-VideoHelperSuite.git"
    )
    .run_commands(
        "cd /root/comfy/ComfyUI/custom_nodes/ComfyUI-VideoHelperSuite && "
        "pip install -r requirements.txt || true"
    )
)

# HuggingFace Secret
try:
    hf_secret = modal.Secret.from_name("huggingface-secret")
except modal.exception.NotFoundError:
    hf_secret = None


# =============================================================================
# S2: æ¨¡å‹ä¸‹è½½å‡½æ•°
# =============================================================================
def download_wan_models():
    """
    ä¸‹è½½ Wan 2.1 T2V æ¨¡å‹:
    - Wan 2.1 T2V 14B ä¸»æ¨¡å‹ (diffusion_models)
    - VAE æ¨¡å‹
    - T5/UMT5 æ–‡æœ¬ç¼–ç å™¨ (FP8 é‡åŒ–ä¼˜å…ˆ)
    """
    from huggingface_hub import hf_hub_download

    hf_token = os.getenv("HF_TOKEN")
    print(f"ğŸ”‘ HuggingFace TokençŠ¶æ€: {'å·²é…ç½®' if hf_token else 'æœªé…ç½®'}")
    print(f"ğŸ“¦ ä» {WAN_MODEL_REPO} ä¸‹è½½ Wan 2.1 T2V æ¨¡å‹...")
    print(f"ğŸ’¡ ä½¿ç”¨ FP8 é‡åŒ–: æ˜¾å­˜éœ€æ±‚ ~30GB, è´¨é‡å‡ ä¹æ— æŸ")

    # Wan 2.1 ä½¿ç”¨çš„æ¨¡å‹ç›®å½•ç»“æ„
    model_dirs = {
        "diffusion_models": "/root/comfy/ComfyUI/models/diffusion_models/wan",
        "vae": "/root/comfy/ComfyUI/models/vae",
        "clip": "/root/comfy/ComfyUI/models/clip",
    }
    
    for dir_path in model_dirs.values():
        os.makedirs(dir_path, exist_ok=True)

    # ä¸‹è½½ä¸»æ¨¡å‹ (Wan 2.1 T2V 14B)
    print("ğŸ“¥ ä¸‹è½½ Wan 2.1 T2V ä¸»æ¨¡å‹...")
    model_files = [
        "diffusion_models/wan2.1_t2v_14B_fp8_e4m3fn.safetensors",
        "wan2.1_t2v_14B_fp8_e4m3fn.safetensors",
        "diffusion_models/wan2.1_t2v_14B_fp8.safetensors",
        "wan2.1_t2v_14B_fp8.safetensors",
        "diffusion_models/wan2.1_t2v_14B_fp16.safetensors",
        "wan2.1_t2v_14B_fp16.safetensors",
        "wan2.1_t2v_14B.safetensors",
    ]
    
    model_downloaded = False
    for model_file in model_files:
        try:
            main_model = hf_hub_download(
                repo_id=WAN_MODEL_REPO,
                filename=model_file,
                cache_dir="/cache",
                token=hf_token
            )
            model_basename = os.path.basename(model_file)
            target = f"{model_dirs['diffusion_models']}/{model_basename}"
            subprocess.run(f"ln -sf {main_model} {target}", shell=True, check=True)
            print(f"   âœ… ä¸»æ¨¡å‹å®Œæˆ: {model_basename}")
            model_downloaded = True
            break
        except Exception as e:
            continue
    
    if not model_downloaded:
        print(f"   âš ï¸ 14B æ¨¡å‹ä¸‹è½½å¤±è´¥ï¼Œå°è¯• 1.3B è½»é‡ç‰ˆ...")
        lite_files = ["wan2.1_t2v_1.3B_fp16.safetensors"]
        for lite_file in lite_files:
            try:
                lite_model = hf_hub_download(
                    repo_id=WAN_MODEL_REPO_LITE,
                    filename=lite_file,
                    cache_dir="/cache",
                    token=hf_token
                )
                lite_basename = os.path.basename(lite_file)
                target = f"{model_dirs['diffusion_models']}/{lite_basename}"
                subprocess.run(f"ln -sf {lite_model} {target}", shell=True, check=True)
                print(f"   âœ… è½»é‡æ¨¡å‹å®Œæˆ: {lite_basename}")
                model_downloaded = True
                break
            except Exception as e:
                continue

    # ä¸‹è½½ VAE æ¨¡å‹
    print("ğŸ“¥ ä¸‹è½½ VAE æ¨¡å‹...")
    vae_files = ["vae/wan_2.1_vae.safetensors", "wan_2.1_vae.safetensors"]
    for vae_file in vae_files:
        try:
            vae_model = hf_hub_download(
                repo_id=WAN_MODEL_REPO,
                filename=vae_file,
                cache_dir="/cache",
                token=hf_token
            )
            target = f"{model_dirs['vae']}/wan_2.1_vae.safetensors"
            subprocess.run(f"ln -sf {vae_model} {target}", shell=True, check=True)
            print(f"   âœ… VAE å®Œæˆ")
            break
        except Exception as e:
            continue

    # ä¸‹è½½ CLIP æ–‡æœ¬ç¼–ç å™¨
    print("ğŸ“¥ ä¸‹è½½ CLIP æ–‡æœ¬ç¼–ç å™¨...")
    clip_files = [
        "text_encoders/umt5_xxl_fp8_e4m3fn.safetensors",
        "umt5_xxl_fp8_e4m3fn.safetensors",
        "text_encoders/umt5_xxl_fp16.safetensors",
        "umt5_xxl_fp16.safetensors",
    ]
    for clip_file in clip_files:
        try:
            clip_model = hf_hub_download(
                repo_id=WAN_MODEL_REPO,
                filename=clip_file,
                cache_dir="/cache",
                token=hf_token
            )
            clip_basename = os.path.basename(clip_file)
            target = f"{model_dirs['clip']}/{clip_basename}"
            subprocess.run(f"ln -sf {clip_model} {target}", shell=True, check=True)
            print(f"   âœ… CLIP å®Œæˆ: {clip_basename}")
            break
        except Exception as e:
            continue

    print("ğŸ‰ æ¨¡å‹ä¸‹è½½æµç¨‹å®Œæˆ!")


def create_workflow_file():
    """åˆ›å»º T2V å·¥ä½œæµ JSON æ–‡ä»¶"""
    workflow = {
        "1": {
            "class_type": "WanVideoModelLoader",
            "inputs": {"model_name": "wan2.1_t2v_14B_fp16.safetensors", "weight_dtype": "fp16"}
        },
        "2": {
            "class_type": "WanVideoVAELoader",
            "inputs": {"vae_name": "wan_2.1_vae.safetensors"}
        },
        "3": {
            "class_type": "WanVideoTextEncode",
            "inputs": {
                "model": ["1", 0],
                "positive_prompt": "A serene landscape with mountains and flowing river, cinematic, 4K",
                "negative_prompt": "low quality, blurry, distorted, watermark"
            }
        },
        "4": {
            "class_type": "WanVideoSampler",
            "inputs": {
                "model": ["1", 0], "vae": ["2", 0], "conditioning": ["3", 0],
                "width": 1280, "height": 720, "num_frames": 81,
                "steps": 30, "cfg": 5.0, "seed": 42, "denoise": 1.0
            }
        },
        "5": {
            "class_type": "VHS_VideoCombine",
            "inputs": {
                "images": ["4", 0], "frame_rate": 16,
                "format": "video/h264-mp4", "filename_prefix": "wan21_t2v"
            }
        }
    }
    Path("/root/workflow_wan21_t2v.json").write_text(json.dumps(workflow, ensure_ascii=False, indent=2))
    print(f"ğŸ“ T2V å·¥ä½œæµæ–‡ä»¶å·²åˆ›å»º")


# =============================================================================
# S3: æœåŠ¡é…ç½®
# =============================================================================
vol = modal.Volume.from_name(MODEL_VOLUME_NAME, create_if_missing=True)

image = (
    image.pip_install("huggingface_hub[hf_transfer]==0.34.4")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        download_wan_models,
        volumes={"/cache": vol},
        secrets=[hf_secret] if hf_secret else [],
        gpu="L40S",
        timeout=7200
    )
    .run_function(create_workflow_file)
)

app = modal.App(name="wan21-t2v-server", image=image)


# =============================================================================
# S4: UI æœåŠ¡ (ComfyUI Web ç•Œé¢)
# =============================================================================
@app.function(
    max_containers=1,
    gpu="L40S",
    volumes={"/cache": vol},
    timeout=86400,
    container_idle_timeout=600,
)
@modal.concurrent(max_inputs=1)
@modal.web_server(UI_PORT, startup_timeout=180)
def ui():
    """ComfyUI Web ç•Œé¢ - Wan 2.1 T2V"""
    print(f"ğŸ¬ å¯åŠ¨ Wan 2.1 T2V Web ç•Œé¢ (ç«¯å£: {UI_PORT})...")
    subprocess.Popen(f"comfy launch -- --listen 0.0.0.0 --port {UI_PORT}", shell=True)


# =============================================================================
# S5: æœ¬åœ°å…¥å£ç‚¹
# =============================================================================
@app.local_entrypoint()
def main():
    print("=" * 60)
    print("ğŸ¬ Wan 2.1 T2V (Text-to-Video) ComfyUI ä¸€é”®éƒ¨ç½²")
    print("=" * 60)
    print(f"\nğŸ“¦ æ¨¡å‹æ¥æº: HuggingFace {WAN_MODEL_REPO}")
    print(f"\nğŸ”§ é…ç½®:")
    print(f"   - Volume: {MODEL_VOLUME_NAME}")
    print(f"   - UI ç«¯å£: {UI_PORT}")
    print(f"   - GPU: {GPU_TYPE} (48GB)")
    print(f"\nğŸ“Œ éƒ¨ç½²å‘½ä»¤: modal deploy wan21_t2v_deploy.py")
    print("=" * 60)
