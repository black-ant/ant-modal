"""
æ–‡æœ¬åµŒå…¥æœåŠ¡
ä½¿ç”¨ Sentence Transformers ç”Ÿæˆæ–‡æœ¬å‘é‡
ç”¨äºè¯­ä¹‰æœç´¢ã€ç›¸ä¼¼åº¦è®¡ç®—ç­‰
"""
import modal

app = modal.App("embedding-service")

# æ„å»ºé•œåƒ
image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "sentence-transformers",
        "torch==2.1.0",
    )
)

# æ¨¡å‹ç¼“å­˜
model_volume = modal.Volume.from_name("embedding-models", create_if_missing=True)


@app.cls(
    image=image,
    gpu="T4",
    volumes={"/models": model_volume},
    timeout=600,
)
class EmbeddingService:
    @modal.enter()
    def load_model(self):
        """åŠ è½½åµŒå…¥æ¨¡å‹"""
        from sentence_transformers import SentenceTransformer
        
        print("ğŸ”¤ åŠ è½½åµŒå…¥æ¨¡å‹...")
        
        # ä½¿ç”¨å¤šè¯­è¨€æ¨¡å‹
        self.model = SentenceTransformer(
            "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
            cache_folder="/models"
        )
        
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @modal.method()
    def encode(self, texts: list[str]) -> list[list[float]]:
        """
        ç”Ÿæˆæ–‡æœ¬åµŒå…¥å‘é‡
        
        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
        
        Returns:
            åµŒå…¥å‘é‡åˆ—è¡¨
        """
        print(f"ğŸ”¤ ç”Ÿæˆ {len(texts)} ä¸ªæ–‡æœ¬çš„åµŒå…¥å‘é‡...")
        
        embeddings = self.model.encode(
            texts,
            convert_to_numpy=True,
            show_progress_bar=False
        )
        
        print("âœ“ åµŒå…¥å‘é‡ç”Ÿæˆå®Œæˆ")
        return embeddings.tolist()
    
    @modal.method()
    def similarity(self, text1: str, text2: str) -> float:
        """
        è®¡ç®—ä¸¤ä¸ªæ–‡æœ¬çš„ç›¸ä¼¼åº¦
        
        Args:
            text1: æ–‡æœ¬1
            text2: æ–‡æœ¬2
        
        Returns:
            ç›¸ä¼¼åº¦åˆ†æ•° (0-1)
        """
        from sklearn.metrics.pairwise import cosine_similarity
        import numpy as np
        
        embeddings = self.model.encode([text1, text2])
        similarity = cosine_similarity(
            embeddings[0].reshape(1, -1),
            embeddings[1].reshape(1, -1)
        )[0][0]
        
        return float(similarity)
    
    @modal.method()
    def search(
        self,
        query: str,
        documents: list[str],
        top_k: int = 5
    ) -> list[dict]:
        """
        è¯­ä¹‰æœç´¢
        
        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            documents: æ–‡æ¡£åˆ—è¡¨
            top_k: è¿”å›å‰ k ä¸ªç»“æœ
        
        Returns:
            ç›¸ä¼¼æ–‡æ¡£åˆ—è¡¨
        """
        from sklearn.metrics.pairwise import cosine_similarity
        import numpy as np
        
        print(f"ğŸ” åœ¨ {len(documents)} ä¸ªæ–‡æ¡£ä¸­æœç´¢...")
        
        # ç”ŸæˆåµŒå…¥
        query_embedding = self.model.encode([query])[0]
        doc_embeddings = self.model.encode(documents)
        
        # è®¡ç®—ç›¸ä¼¼åº¦
        similarities = cosine_similarity(
            query_embedding.reshape(1, -1),
            doc_embeddings
        )[0]
        
        # æ’åºå¹¶è¿”å› top_k
        top_indices = np.argsort(similarities)[::-1][:top_k]
        
        results = [
            {
                "index": int(idx),
                "text": documents[idx],
                "score": float(similarities[idx])
            }
            for idx in top_indices
        ]
        
        print(f"âœ“ æ‰¾åˆ° {len(results)} ä¸ªç›¸å…³æ–‡æ¡£")
        return results


@app.function(image=image)
@modal.web_endpoint(method="POST")
def embed_texts(data: dict):
    """
    Web API: ç”ŸæˆåµŒå…¥å‘é‡
    
    POST /embed_texts
    {
        "texts": ["text1", "text2", ...]
    }
    """
    service = EmbeddingService()
    embeddings = service.encode.remote(data["texts"])
    return {"embeddings": embeddings}


@app.function(image=image)
@modal.web_endpoint(method="POST")
def semantic_search(data: dict):
    """
    Web API: è¯­ä¹‰æœç´¢
    
    POST /semantic_search
    {
        "query": "search query",
        "documents": ["doc1", "doc2", ...],
        "top_k": 5
    }
    """
    service = EmbeddingService()
    results = service.search.remote(
        query=data["query"],
        documents=data["documents"],
        top_k=data.get("top_k", 5)
    )
    return {"results": results}


@app.local_entrypoint()
def main():
    """æœ¬åœ°æµ‹è¯•"""
    service = EmbeddingService()
    
    # æµ‹è¯•æ–‡æ¡£
    documents = [
        "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œ",
        "æœºå™¨å­¦ä¹ æ˜¯AIçš„ä¸€ä¸ªåˆ†æ”¯",
        "ä»Šå¤©å¤©æ°”å¾ˆå¥½",
        "æ·±åº¦å­¦ä¹ ä½¿ç”¨ç¥ç»ç½‘ç»œ",
        "æˆ‘å–œæ¬¢åƒæŠ«è¨"
    ]
    
    query = "AIæŠ€æœ¯çš„å‘å±•"
    
    print(f"æŸ¥è¯¢: {query}\n")
    results = service.search.remote(query, documents, top_k=3)
    
    print("æœç´¢ç»“æœ:")
    for i, result in enumerate(results, 1):
        print(f"{i}. [{result['score']:.3f}] {result['text']}")
