"""
06 - GPU è®¡ç®—
å­¦ä¹ ç›®æ ‡ï¼šç†è§£å¦‚ä½•åœ¨ Modal ä¸­ä½¿ç”¨ GPU

è¿™ä¸ªä¾‹å­å±•ç¤ºï¼š
- å¦‚ä½•è¯·æ±‚ GPU èµ„æº
- å¦‚ä½•ä½¿ç”¨ PyTorch è¿›è¡Œ GPU è®¡ç®—
- GPU å’Œ CPU çš„æ€§èƒ½å¯¹æ¯”
"""
import modal

app = modal.App("gpu-computing-demo")

# æ„å»ºåŒ…å« PyTorch çš„é•œåƒ
image = modal.Image.debian_slim().pip_install("torch", "numpy")


@app.function(image=image, gpu="T4")
def gpu_matrix_multiply(size: int = 1000):
    """
    ä½¿ç”¨ GPU è¿›è¡ŒçŸ©é˜µä¹˜æ³•
    T4 æ˜¯å…¥é—¨çº§ GPUï¼Œé€‚åˆå­¦ä¹ å’Œå°è§„æ¨¡è®¡ç®—
    """
    import torch
    import time
    
    print(f"ğŸ® ä½¿ç”¨ GPU è®¡ç®— {size}x{size} çŸ©é˜µä¹˜æ³•...")
    
    # æ£€æŸ¥ GPU æ˜¯å¦å¯ç”¨
    device = "cuda" if torch.cuda.is_available() else "cpu"
    print(f"è®¾å¤‡: {device}")
    
    if device == "cuda":
        print(f"GPU å‹å·: {torch.cuda.get_device_name(0)}")
    
    # åˆ›å»ºéšæœºçŸ©é˜µ
    a = torch.randn(size, size, device=device)
    b = torch.randn(size, size, device=device)
    
    # è®¡æ—¶
    start = time.time()
    c = torch.matmul(a, b)
    torch.cuda.synchronize() if device == "cuda" else None
    elapsed = time.time() - start
    
    return {
        "device": device,
        "size": size,
        "time": f"{elapsed:.4f} ç§’",
        "performance": f"{(size**3 * 2) / elapsed / 1e9:.2f} GFLOPS"
    }


@app.function(image=image)
def cpu_matrix_multiply(size: int = 1000):
    """
    ä½¿ç”¨ CPU è¿›è¡Œç›¸åŒçš„è®¡ç®—ï¼ˆå¯¹æ¯”ï¼‰
    """
    import torch
    import time
    
    print(f"ğŸ’» ä½¿ç”¨ CPU è®¡ç®— {size}x{size} çŸ©é˜µä¹˜æ³•...")
    
    a = torch.randn(size, size)
    b = torch.randn(size, size)
    
    start = time.time()
    c = torch.matmul(a, b)
    elapsed = time.time() - start
    
    return {
        "device": "cpu",
        "size": size,
        "time": f"{elapsed:.4f} ç§’",
        "performance": f"{(size**3 * 2) / elapsed / 1e9:.2f} GFLOPS"
    }


@app.local_entrypoint()
def main():
    """
    å¯¹æ¯” GPU å’Œ CPU çš„æ€§èƒ½
    """
    print("ğŸ® GPU vs CPU æ€§èƒ½å¯¹æ¯”")
    print("=" * 50)
    
    size = 2000
    
    print(f"\næµ‹è¯•: {size}x{size} çŸ©é˜µä¹˜æ³•\n")
    
    # GPU è®¡ç®—
    print("1ï¸âƒ£ GPU è®¡ç®—:")
    gpu_result = gpu_matrix_multiply.remote(size)
    print(f"   è®¾å¤‡: {gpu_result['device']}")
    print(f"   è€—æ—¶: {gpu_result['time']}")
    print(f"   æ€§èƒ½: {gpu_result['performance']}")
    
    # CPU è®¡ç®—
    print("\n2ï¸âƒ£ CPU è®¡ç®—:")
    cpu_result = cpu_matrix_multiply.remote(size)
    print(f"   è®¾å¤‡: {cpu_result['device']}")
    print(f"   è€—æ—¶: {cpu_result['time']}")
    print(f"   æ€§èƒ½: {cpu_result['performance']}")
    
    print("\nğŸ’¡ æç¤º:")
    print("- T4: å…¥é—¨çº§ GPUï¼Œé€‚åˆå­¦ä¹ å’Œå¼€å‘")
    print("- A10G: ä¸­ç«¯ GPUï¼Œé€‚åˆç”Ÿäº§ç¯å¢ƒ")
    print("- A100: é«˜ç«¯ GPUï¼Œé€‚åˆå¤§è§„æ¨¡è®­ç»ƒ")
    print("- H100: æœ€æ–°æœ€å¼º GPUï¼Œé€‚åˆå‰æ²¿ç ”ç©¶")
