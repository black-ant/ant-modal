"""
è§†é¢‘å­—å¹•è‡ªåŠ¨ç”Ÿæˆ
ä¸šåŠ¡åœºæ™¯ï¼šè§†é¢‘å¹³å°/è‡ªåª’ä½“éœ€è¦ä¸ºè§†é¢‘æ·»åŠ å­—å¹•

è§£å†³çš„é—®é¢˜ï¼š
- æ‰‹åŠ¨æ·»åŠ å­—å¹•æ¯å°æ—¶è§†é¢‘éœ€è¦ 4-6 å°æ—¶
- å¤–åŒ…å­—å¹•æˆæœ¬é«˜ï¼Œè´¨é‡ä¸ç¨³å®š
- å¤šè¯­è¨€å­—å¹•éœ€æ±‚å¢åŠ ï¼Œäººå·¥å¤„ç†éš¾ä»¥æ»¡è¶³

è¿™ä¸ªä¾‹å­å±•ç¤ºï¼š
- ä»è§†é¢‘ä¸­æå–éŸ³é¢‘å¹¶è½¬å½•
- ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„ SRT å­—å¹•æ–‡ä»¶
- æ”¯æŒå¤šè¯­è¨€è½¬å½•å’Œç¿»è¯‘
- æ‰¹é‡å¤„ç†å¤šä¸ªè§†é¢‘
"""
import modal
import io
from datetime import datetime

app = modal.App("whisper-subtitle")

image = (
    modal.Image.debian_slim(python_version="3.11")
    .apt_install("ffmpeg")
    .pip_install(
        "openai-whisper",
        "torch==2.1.0",
    )
)

model_volume = modal.Volume.from_name("whisper-models", create_if_missing=True)
output_volume = modal.Volume.from_name("video-subtitles", create_if_missing=True)


def format_timestamp(seconds: float) -> str:
    """å°†ç§’æ•°è½¬æ¢ä¸º SRT æ—¶é—´æˆ³æ ¼å¼ (HH:MM:SS,mmm)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


def generate_srt(segments: list[dict]) -> str:
    """ç”Ÿæˆ SRT æ ¼å¼å­—å¹•"""
    srt_content = []
    
    for i, seg in enumerate(segments, 1):
        start_time = format_timestamp(seg["start"])
        end_time = format_timestamp(seg["end"])
        text = seg["text"].strip()
        
        srt_content.append(f"{i}")
        srt_content.append(f"{start_time} --> {end_time}")
        srt_content.append(text)
        srt_content.append("")  # ç©ºè¡Œåˆ†éš”
    
    return "\n".join(srt_content)


def generate_vtt(segments: list[dict]) -> str:
    """ç”Ÿæˆ WebVTT æ ¼å¼å­—å¹•"""
    vtt_content = ["WEBVTT", ""]
    
    for i, seg in enumerate(segments, 1):
        start_time = format_timestamp(seg["start"]).replace(",", ".")
        end_time = format_timestamp(seg["end"]).replace(",", ".")
        text = seg["text"].strip()
        
        vtt_content.append(f"{i}")
        vtt_content.append(f"{start_time} --> {end_time}")
        vtt_content.append(text)
        vtt_content.append("")
    
    return "\n".join(vtt_content)


@app.cls(
    image=image,
    gpu="T4",
    volumes={"/models": model_volume, "/output": output_volume},
    timeout=1800,
)
class SubtitleGenerator:
    @modal.enter()
    def load_model(self):
        import whisper
        
        print("ğŸ¤ åŠ è½½ Whisper æ¨¡å‹...")
        # large æ¨¡å‹ç²¾åº¦æ›´é«˜ï¼Œé€‚åˆå­—å¹•ç”Ÿæˆ
        self.model = whisper.load_model("medium", download_root="/models")
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @modal.method()
    def generate_subtitle(
        self,
        audio_data: bytes,
        language: str = None,
        task: str = "transcribe",
        output_format: str = "srt"
    ) -> dict:
        """
        ç”Ÿæˆè§†é¢‘å­—å¹•
        
        Args:
            audio_data: éŸ³é¢‘æ•°æ®ï¼ˆå¯ä»è§†é¢‘æå–ï¼‰
            language: æºè¯­è¨€ï¼ˆNone è‡ªåŠ¨æ£€æµ‹ï¼‰
            task: "transcribe"(è½¬å½•) æˆ– "translate"(ç¿»è¯‘æˆè‹±æ–‡)
            output_format: "srt" æˆ– "vtt"
        
        Returns:
            å­—å¹•å†…å®¹å’Œå…ƒæ•°æ®
        """
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            f.write(audio_data)
            temp_path = f.name
        
        try:
            print(f"ğŸ¬ ç”Ÿæˆå­—å¹• (è¯­è¨€: {language or 'è‡ªåŠ¨æ£€æµ‹'}, ä»»åŠ¡: {task})")
            
            result = self.model.transcribe(
                temp_path,
                language=language,
                task=task,
                fp16=True,
                verbose=False
            )
            
            segments = [
                {
                    "start": seg["start"],
                    "end": seg["end"],
                    "text": seg["text"]
                }
                for seg in result.get("segments", [])
            ]
            
            # ç”Ÿæˆå­—å¹•æ–‡ä»¶
            if output_format == "vtt":
                subtitle_content = generate_vtt(segments)
            else:
                subtitle_content = generate_srt(segments)
            
            duration = segments[-1]["end"] if segments else 0
            
            print(f"âœ“ å­—å¹•ç”Ÿæˆå®Œæˆ: {len(segments)} æ¡, {duration/60:.1f} åˆ†é’Ÿ")
            
            return {
                "subtitle": subtitle_content,
                "format": output_format,
                "language": result.get("language"),
                "segments_count": len(segments),
                "duration_seconds": duration,
                "segments": segments  # åŸå§‹åˆ†æ®µæ•°æ®
            }
            
        finally:
            os.unlink(temp_path)
    
    @modal.method()
    def generate_bilingual_subtitle(
        self,
        audio_data: bytes,
        source_language: str = "zh",
        output_format: str = "srt"
    ) -> dict:
        """
        ç”ŸæˆåŒè¯­å­—å¹•ï¼ˆåŸæ–‡ + è‹±æ–‡ç¿»è¯‘ï¼‰
        """
        import tempfile
        import os
        
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as f:
            f.write(audio_data)
            temp_path = f.name
        
        try:
            # è½¬å½•åŸæ–‡
            print("ğŸ¬ è½¬å½•åŸæ–‡...")
            original = self.model.transcribe(
                temp_path,
                language=source_language,
                task="transcribe",
                fp16=True
            )
            
            # ç¿»è¯‘æˆè‹±æ–‡
            print("ğŸŒ ç¿»è¯‘æˆè‹±æ–‡...")
            translated = self.model.transcribe(
                temp_path,
                language=source_language,
                task="translate",
                fp16=True
            )
            
            # åˆå¹¶åŒè¯­å­—å¹•
            bilingual_segments = []
            for orig_seg, trans_seg in zip(
                original.get("segments", []),
                translated.get("segments", [])
            ):
                bilingual_segments.append({
                    "start": orig_seg["start"],
                    "end": orig_seg["end"],
                    "text": f"{orig_seg['text'].strip()}\n{trans_seg['text'].strip()}"
                })
            
            if output_format == "vtt":
                subtitle_content = generate_vtt(bilingual_segments)
            else:
                subtitle_content = generate_srt(bilingual_segments)
            
            return {
                "subtitle": subtitle_content,
                "format": output_format,
                "type": "bilingual",
                "source_language": source_language,
                "segments_count": len(bilingual_segments)
            }
            
        finally:
            os.unlink(temp_path)


@app.function(
    image=image,
    volumes={"/output": output_volume},
    timeout=3600
)
def batch_generate_subtitles(
    videos: list[dict],
    language: str = None,
    output_format: str = "srt"
) -> dict:
    """
    æ‰¹é‡ç”Ÿæˆå­—å¹•
    
    Args:
        videos: è§†é¢‘åˆ—è¡¨ [{"name": "video1", "audio_data": bytes}]
        language: è¯­è¨€
        output_format: è¾“å‡ºæ ¼å¼
    """
    import os
    
    generator = SubtitleGenerator()
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_dir = f"/output/batch_{timestamp}"
    os.makedirs(output_dir, exist_ok=True)
    
    results = {
        "total": len(videos),
        "success": 0,
        "failed": 0,
        "files": []
    }
    
    print(f"ğŸ¬ æ‰¹é‡ç”Ÿæˆå­—å¹•: {len(videos)} ä¸ªè§†é¢‘")
    
    for i, video in enumerate(videos, 1):
        print(f"\n[{i}/{len(videos)}] å¤„ç†: {video['name']}")
        
        try:
            result = generator.generate_subtitle.remote(
                audio_data=video["audio_data"],
                language=language,
                output_format=output_format
            )
            
            # ä¿å­˜å­—å¹•æ–‡ä»¶
            ext = "vtt" if output_format == "vtt" else "srt"
            filename = f"{video['name']}.{ext}"
            filepath = f"{output_dir}/{filename}"
            
            with open(filepath, "w", encoding="utf-8") as f:
                f.write(result["subtitle"])
            
            results["files"].append({
                "video": video["name"],
                "subtitle_file": filename,
                "segments": result["segments_count"],
                "duration": result["duration_seconds"]
            })
            results["success"] += 1
            
            print(f"  âœ“ å®Œæˆ: {result['segments_count']} æ¡å­—å¹•")
            
        except Exception as e:
            results["failed"] += 1
            print(f"  âœ— å¤±è´¥: {str(e)}")
    
    output_volume.commit()
    
    print(f"\nâœ… æ‰¹é‡å¤„ç†å®Œæˆ: {results['success']} æˆåŠŸ, {results['failed']} å¤±è´¥")
    return results


@app.function(image=image)
@modal.web_endpoint(method="POST")
def subtitle_api(
    audio: bytes,
    language: str = None,
    format: str = "srt",
    bilingual: bool = False
):
    """
    å­—å¹•ç”Ÿæˆ API
    
    POST /subtitle_api
    Content-Type: audio/*
    Query params:
    - language: æºè¯­è¨€ (zh, en, ja ç­‰)
    - format: srt æˆ– vtt
    - bilingual: true ç”ŸæˆåŒè¯­å­—å¹•
    """
    generator = SubtitleGenerator()
    
    if bilingual:
        result = generator.generate_bilingual_subtitle.remote(
            audio_data=audio,
            source_language=language or "zh",
            output_format=format
        )
    else:
        result = generator.generate_subtitle.remote(
            audio_data=audio,
            language=language,
            output_format=format
        )
    
    return {
        "status": "success",
        "subtitle": result["subtitle"],
        "format": result["format"],
        "segments_count": result["segments_count"]
    }


@app.local_entrypoint()
def main():
    """ä½¿ç”¨è¯´æ˜"""
    print("ğŸ¬ è§†é¢‘å­—å¹•è‡ªåŠ¨ç”Ÿæˆ")
    print("=" * 50)
    print("\nä½¿ç”¨æ–¹æ³•:")
    print("1. éƒ¨ç½²æœåŠ¡: modal deploy whisper_subtitle.py")
    print("\n2. è°ƒç”¨ API ç”Ÿæˆå­—å¹•:")
    print("   curl -X POST -H 'Content-Type: audio/mp3' \\")
    print("        --data-binary @video_audio.mp3 \\")
    print("        'https://your-app--subtitle-api.modal.run?format=srt'")
    print("\n3. ç”ŸæˆåŒè¯­å­—å¹•:")
    print("   ...?language=zh&bilingual=true")
    print("\nğŸ’¡ æç¤º:")
    print("1. æ”¯æŒ SRT å’Œ WebVTT ä¸¤ç§æ ¼å¼")
    print("2. å¯å…ˆç”¨ ffmpeg ä»è§†é¢‘æå–éŸ³é¢‘")
    print("3. åŒè¯­å­—å¹•é€‚åˆå­¦ä¹ ç±»/å›½é™…åŒ–è§†é¢‘")

