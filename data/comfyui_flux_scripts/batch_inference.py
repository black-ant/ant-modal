"""
æ‰¹é‡å›¾åƒç”Ÿæˆå·¥å…·
æ”¯æŒå¹¶è¡Œå¤„ç†å¤šä¸ªæç¤ºè¯ï¼Œæé«˜æ•ˆç‡
å‚è€ƒ Modal çš„ map/starmap å¹¶è¡Œå¤„ç†æ¨¡å¼
"""

import modal
import json
from pathlib import Path
from config import *
from model_download import download_all_models
from api_service import start_comfy_background, handle_api_request

# æ„å»ºé•œåƒï¼ˆä¸ä¸»åº”ç”¨ç›¸åŒï¼‰
image = build_base_image()
image = install_custom_nodes(image)

hf_secret = get_hf_secret()
vol = get_volume()

image = (
    image.pip_install("huggingface_hub[hf_transfer]==0.34.4")
    .env({"HF_HUB_ENABLE_HF_TRANSFER": "1"})
    .run_function(
        download_all_models,
        volumes={"/cache": vol},
        secrets=[hf_secret]
    )
    .add_local_file(
        Path(__file__).parent / "workflow_api.json",
        "/root/workflow_api.json"
    )
)

app = modal.App("comfyui-batch-processor", image=image)


@app.cls(
    gpu=GPU_TYPE,
    volumes={"/cache": vol},
    timeout=3600,  # 1å°æ—¶è¶…æ—¶
    container_idle_timeout=600  # å®¹å™¨ç©ºé—²10åˆ†é’Ÿåå›æ”¶
)
class BatchImageGenerator:
    """æ‰¹é‡å›¾åƒç”Ÿæˆå™¨ç±»"""
    
    @modal.enter()
    def startup(self):
        """å®¹å™¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
        print("ğŸš€ å¯åŠ¨æ‰¹é‡å›¾åƒç”Ÿæˆå™¨...")
        start_comfy_background(API_PORT)
        print("âœ… ComfyUI åå°æœåŠ¡å·²å°±ç»ª")
    
    @modal.method()
    def generate_single(
        self, 
        prompt: str, 
        workflow_path: str = "/root/workflow_api.json",
        **kwargs
    ) -> bytes:
        """
        ç”Ÿæˆå•å¼ å›¾ç‰‡
        
        Args:
            prompt: æç¤ºè¯
            workflow_path: å·¥ä½œæµæ¨¡æ¿è·¯å¾„
            **kwargs: å…¶ä»–å‚æ•°ï¼ˆwidth, height, stepsç­‰ï¼‰
        
        Returns:
            bytes: å›¾ç‰‡å­—èŠ‚æ•°æ®
        """
        print(f"ğŸ“¸ ç”Ÿæˆå›¾ç‰‡: {prompt[:50]}...")
        
        # å¤„ç†è‡ªå®šä¹‰å‚æ•°
        workflow_data = json.loads(Path(workflow_path).read_text())
        
        # åº”ç”¨è‡ªå®šä¹‰å‚æ•°
        if 'width' in kwargs or 'height' in kwargs:
            width = kwargs.get('width', 832)
            height = kwargs.get('height', 1216)
            workflow_data["27"]["inputs"]["width"] = width
            workflow_data["27"]["inputs"]["height"] = height
        
        if 'steps' in kwargs:
            workflow_data["31"]["inputs"]["steps"] = kwargs['steps']
        
        if 'cfg' in kwargs:
            workflow_data["31"]["inputs"]["cfg"] = kwargs['cfg']
        
        # ç”Ÿæˆå›¾ç‰‡
        img_bytes = handle_api_request(prompt, Path(workflow_path))
        
        return img_bytes
    
    @modal.method()
    def generate_batch(
        self, 
        prompts: list[str],
        workflow_path: str = "/root/workflow_api.json",
        **kwargs
    ) -> list[dict]:
        """
        æ‰¹é‡ç”Ÿæˆå›¾ç‰‡ï¼ˆå•ä¸ªå®¹å™¨å†…ä¸²è¡Œå¤„ç†ï¼‰
        
        Args:
            prompts: æç¤ºè¯åˆ—è¡¨
            workflow_path: å·¥ä½œæµæ¨¡æ¿è·¯å¾„
            **kwargs: å…¶ä»–å‚æ•°
        
        Returns:
            list[dict]: ç»“æœåˆ—è¡¨
        """
        results = []
        
        for i, prompt in enumerate(prompts):
            try:
                print(f"\n[{i+1}/{len(prompts)}] å¤„ç†: {prompt[:50]}...")
                img_bytes = self.generate_single.local(prompt, workflow_path, **kwargs)
                
                results.append({
                    "success": True,
                    "prompt": prompt,
                    "image_size": len(img_bytes),
                    "index": i
                })
                
                print(f"âœ… å®Œæˆ [{i+1}/{len(prompts)}]")
                
            except Exception as e:
                print(f"âŒ å¤±è´¥ [{i+1}/{len(prompts)}]: {e}")
                results.append({
                    "success": False,
                    "prompt": prompt,
                    "error": str(e),
                    "index": i
                })
        
        return results


@app.function(
    gpu=GPU_TYPE,
    volumes={"/cache": vol},
    timeout=1800
)
def generate_image_parallel(
    prompt: str,
    width: int = 832,
    height: int = 1216,
    steps: int = 20,
    cfg: float = 1.0
) -> dict:
    """
    å¹¶è¡Œå›¾åƒç”Ÿæˆå‡½æ•°ï¼ˆç”¨äº mapï¼‰
    
    Args:
        prompt: æç¤ºè¯
        width: å›¾ç‰‡å®½åº¦
        height: å›¾ç‰‡é«˜åº¦
        steps: é‡‡æ ·æ­¥æ•°
        cfg: CFG å¼ºåº¦
    
    Returns:
        dict: ç”Ÿæˆç»“æœ
    """
    try:
        # å¯åŠ¨ ComfyUI
        start_comfy_background(API_PORT)
        
        # å‡†å¤‡å·¥ä½œæµ
        workflow_data = json.loads(Path("/root/workflow_api.json").read_text())
        workflow_data["27"]["inputs"]["width"] = width
        workflow_data["27"]["inputs"]["height"] = height
        workflow_data["31"]["inputs"]["steps"] = steps
        workflow_data["31"]["inputs"]["cfg"] = cfg
        
        # ç”Ÿæˆå›¾ç‰‡
        img_bytes = handle_api_request(prompt, Path("/root/workflow_api.json"))
        
        return {
            "success": True,
            "prompt": prompt,
            "image_size": len(img_bytes),
            "parameters": {
                "width": width,
                "height": height,
                "steps": steps,
                "cfg": cfg
            }
        }
    except Exception as e:
        return {
            "success": False,
            "prompt": prompt,
            "error": str(e)
        }


@app.local_entrypoint()
def main(
    prompts_file: str = "",
    prompt: str = "",
    parallel: bool = False,
    width: int = 832,
    height: int = 1216,
    steps: int = 20,
    cfg: float = 1.0
):
    """
    æ‰¹é‡ç”Ÿæˆå›¾ç‰‡å…¥å£
    
    ä½¿ç”¨ç¤ºä¾‹:
    # å•ä¸ªæç¤ºè¯
    modal run batch_inference.py --prompt "A beautiful landscape"
    
    # ä»æ–‡ä»¶è¯»å–å¤šä¸ªæç¤ºè¯ï¼ˆæ¯è¡Œä¸€ä¸ªï¼‰
    modal run batch_inference.py --prompts-file prompts.txt
    
    # å¹¶è¡Œæ¨¡å¼ï¼ˆæ¯ä¸ªæç¤ºè¯ç‹¬ç«‹å®¹å™¨ï¼‰
    modal run batch_inference.py --prompts-file prompts.txt --parallel
    
    # è‡ªå®šä¹‰å‚æ•°
    modal run batch_inference.py --prompt "A cat" --width 1024 --height 1024 --steps 30
    """
    
    # å‡†å¤‡æç¤ºè¯åˆ—è¡¨
    prompts = []
    if prompts_file:
        with open(prompts_file, 'r', encoding='utf-8') as f:
            prompts = [line.strip() for line in f if line.strip()]
        print(f"ğŸ“‹ ä»æ–‡ä»¶è¯»å– {len(prompts)} ä¸ªæç¤ºè¯")
    elif prompt:
        prompts = [prompt]
    else:
        print("âŒ é”™è¯¯: éœ€è¦æä¾› --prompt æˆ– --prompts-file å‚æ•°")
        return
    
    print(f"\n{'='*60}")
    print(f"æ‰¹é‡å›¾åƒç”Ÿæˆ")
    print(f"æ¨¡å¼: {'å¹¶è¡Œ' if parallel else 'ä¸²è¡Œ'}")
    print(f"æç¤ºè¯æ•°é‡: {len(prompts)}")
    print(f"å‚æ•°: {width}x{height}, steps={steps}, cfg={cfg}")
    print(f"{'='*60}\n")
    
    if parallel:
        # å¹¶è¡Œæ¨¡å¼ - ä½¿ç”¨ mapï¼Œæ¯ä¸ªæç¤ºè¯ç‹¬ç«‹å®¹å™¨
        print("ğŸš€ ä½¿ç”¨å¹¶è¡Œæ¨¡å¼ï¼ˆæ¯ä¸ªæç¤ºè¯ç‹¬ç«‹å®¹å™¨ï¼‰")
        
        # æ„é€ å‚æ•°å…ƒç»„
        tasks = [
            (p, width, height, steps, cfg) 
            for p in prompts
        ]
        
        # å¹¶è¡Œæ‰§è¡Œ
        results = list(generate_image_parallel.starmap(tasks))
        
    else:
        # ä¸²è¡Œæ¨¡å¼ - å•å®¹å™¨å¤„ç†æ‰€æœ‰æç¤ºè¯
        print("ğŸš€ ä½¿ç”¨ä¸²è¡Œæ¨¡å¼ï¼ˆå•å®¹å™¨å¤„ç†æ‰€æœ‰ï¼‰")
        
        generator = BatchImageGenerator()
        results = generator.generate_batch.remote(
            prompts,
            width=width,
            height=height,
            steps=steps,
            cfg=cfg
        )
    
    # ç»Ÿè®¡ç»“æœ
    successful = sum(1 for r in results if r['success'])
    failed = sum(1 for r in results if not r['success'])
    
    print(f"\n{'='*60}")
    print(f"æ‰¹é‡ç”Ÿæˆå®Œæˆ")
    print(f"{'='*60}")
    print(f"âœ… æˆåŠŸ: {successful}")
    print(f"âŒ å¤±è´¥: {failed}")
    print(f"ğŸ“Š æ€»è®¡: {len(results)}")
    
    # æ˜¾ç¤ºå¤±è´¥çš„ä»»åŠ¡
    if failed > 0:
        print(f"\nå¤±è´¥çš„ä»»åŠ¡:")
        for r in results:
            if not r['success']:
                print(f"  - {r['prompt'][:50]}: {r['error']}")
    
    # ä¿å­˜ç»“æœæ‘˜è¦
    summary = {
        "total": len(results),
        "successful": successful,
        "failed": failed,
        "mode": "parallel" if parallel else "serial",
        "parameters": {
            "width": width,
            "height": height,
            "steps": steps,
            "cfg": cfg
        },
        "results": results
    }
    
    with open("batch_results.json", 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ“„ ç»“æœå·²ä¿å­˜åˆ° batch_results.json")
