"""
å›¾åƒè¯†åˆ«åˆ†ç±»æœåŠ¡
ä½¿ç”¨ ResNet/ViT è¿›è¡Œå›¾åƒåˆ†ç±»

é€‚ç”¨åœºæ™¯ï¼š
- å•†å“å›¾ç‰‡è‡ªåŠ¨åˆ†ç±»
- å†…å®¹å®¡æ ¸å›¾ç‰‡è¯†åˆ«
- å›¾ç‰‡æ ‡ç­¾ç”Ÿæˆ
"""
import modal
import io
import base64

app = modal.App("image-classification")

image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "torch==2.1.0",
        "torchvision",
        "transformers",
        "Pillow",
    )
)

model_volume = modal.Volume.from_name("classifier-models", create_if_missing=True)


@app.cls(
    image=image,
    gpu="T4",
    volumes={"/models": model_volume},
    timeout=300,
)
class ImageClassifier:
    @modal.enter()
    def load_model(self):
        from transformers import AutoImageProcessor, AutoModelForImageClassification
        import torch
        
        print("ğŸ–¼ï¸ åŠ è½½å›¾åƒåˆ†ç±»æ¨¡å‹...")
        
        # ä½¿ç”¨ ViT æ¨¡å‹ï¼ˆä¹Ÿå¯ä»¥æ¢æˆ ResNetï¼‰
        model_name = "google/vit-base-patch16-224"
        
        self.processor = AutoImageProcessor.from_pretrained(
            model_name,
            cache_dir="/models"
        )
        
        self.model = AutoModelForImageClassification.from_pretrained(
            model_name,
            cache_dir="/models"
        )
        self.model.to("cuda")
        self.model.eval()
        
        print("âœ“ æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @modal.method()
    def classify(self, image_data: bytes, top_k: int = 5) -> list[dict]:
        """
        å¯¹å›¾åƒè¿›è¡Œåˆ†ç±»
        
        Args:
            image_data: å›¾åƒäºŒè¿›åˆ¶æ•°æ®
            top_k: è¿”å›å‰ k ä¸ªé¢„æµ‹ç»“æœ
        
        Returns:
            åˆ†ç±»ç»“æœåˆ—è¡¨ [{"label": "cat", "score": 0.95}, ...]
        """
        from PIL import Image
        import torch
        
        # åŠ è½½å›¾åƒ
        img = Image.open(io.BytesIO(image_data)).convert("RGB")
        
        # é¢„å¤„ç†
        inputs = self.processor(img, return_tensors="pt").to("cuda")
        
        # æ¨ç†
        with torch.no_grad():
            outputs = self.model(**inputs)
            probs = torch.nn.functional.softmax(outputs.logits, dim=-1)
        
        # è·å– top_k ç»“æœ
        top_probs, top_indices = probs[0].topk(top_k)
        
        results = []
        for prob, idx in zip(top_probs.cpu().numpy(), top_indices.cpu().numpy()):
            label = self.model.config.id2label[idx]
            results.append({
                "label": label,
                "score": float(prob)
            })
        
        return results
    
    @modal.method()
    def batch_classify(self, images: list[bytes], top_k: int = 5) -> list[list[dict]]:
        """æ‰¹é‡åˆ†ç±»å›¾åƒ"""
        results = []
        for img_data in images:
            result = self.classify(img_data, top_k)
            results.append(result)
        return results


@app.function(image=image)
@modal.web_endpoint(method="POST")
def classify_api(data: dict):
    """
    å›¾åƒåˆ†ç±» API
    
    POST /classify_api
    {
        "image": "base64_encoded_image",
        "top_k": 5
    }
    """
    try:
        image_data = base64.b64decode(data.get("image", ""))
        top_k = data.get("top_k", 5)
        
        classifier = ImageClassifier()
        results = classifier.classify.remote(image_data, top_k)
        
        return {
            "status": "success",
            "predictions": results
        }
    except Exception as e:
        return {"status": "error", "message": str(e)}


@app.local_entrypoint()
def main():
    """æ¼”ç¤ºå›¾åƒåˆ†ç±»"""
    from PIL import Image
    
    print("ğŸ–¼ï¸ å›¾åƒåˆ†ç±»æœåŠ¡")
    print("=" * 50)
    
    # åˆ›å»ºæµ‹è¯•å›¾åƒ
    test_img = Image.new("RGB", (224, 224), color=(255, 100, 100))
    buffer = io.BytesIO()
    test_img.save(buffer, format="JPEG")
    
    classifier = ImageClassifier()
    results = classifier.classify.remote(buffer.getvalue(), top_k=3)
    
    print("\nåˆ†ç±»ç»“æœ:")
    for r in results:
        print(f"  {r['label']}: {r['score']:.2%}")
    
    print("\nğŸ’¡ æç¤º: æ”¯æŒ ImageNet 1000 ç±»åˆ†ç±»")

