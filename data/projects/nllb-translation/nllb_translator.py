"""
NLLB å¤šè¯­è¨€ç¿»è¯‘æœåŠ¡
ä½¿ç”¨ Meta çš„ NLLB (No Language Left Behind) æ¨¡å‹è¿›è¡Œç¿»è¯‘

ä¼˜åŠ¿ï¼š
- æ”¯æŒ 200+ ç§è¯­è¨€äº’è¯‘
- ä¸“é—¨çš„ç¿»è¯‘æ¨¡å‹ï¼Œæ•ˆæœä¼˜äºé€šç”¨ LLM
- èµ„æºéœ€æ±‚ä½ï¼ŒT4 æ˜¾å¡å³å¯è¿è¡Œ
- æ¨ç†é€Ÿåº¦å¿«ï¼Œæˆæœ¬ä½

é€‚ç”¨åœºæ™¯ï¼š
- å¤šè¯­è¨€ç¿»è¯‘æœåŠ¡
- æˆæœ¬æ•æ„Ÿçš„ç¿»è¯‘ä»»åŠ¡
- éœ€è¦å¿«é€Ÿå“åº”çš„ç¿»è¯‘ API
"""
import modal

app = modal.App("nllb-translation")

# è½»é‡çº§é•œåƒé…ç½®
image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "transformers==4.36.0",
        "torch==2.1.0",
        "sentencepiece",
        "sacremoses",
    )
)

# æŒä¹…åŒ–å­˜å‚¨æ¨¡å‹
model_volume = modal.Volume.from_name("nllb-models", create_if_missing=True)


@app.cls(
    image=image,
    gpu="T4",  # T4 æ˜¾å¡è¶³å¤Ÿï¼Œæˆæœ¬ä½
    volumes={"/models": model_volume},
    timeout=600,
    container_idle_timeout=300,
)
class NLLBTranslator:
    """NLLB ç¿»è¯‘æœåŠ¡ç±»"""
    
    @modal.enter()
    def load_model(self):
        """åŠ è½½ NLLB æ¨¡å‹"""
        from transformers import AutoModelForSeq2SeqLM, AutoTokenizer
        import torch
        
        print("ğŸŒ åŠ è½½ NLLB ç¿»è¯‘æ¨¡å‹...")
        
        # ä½¿ç”¨ NLLB-200-distilled-600M ç‰ˆæœ¬ï¼ˆè½»é‡çº§ï¼‰
        # å¦‚éœ€æ›´é«˜è´¨é‡å¯ç”¨ NLLB-200-1.3B æˆ– NLLB-200-3.3B
        model_name = "facebook/nllb-200-distilled-600M"
        
        self.tokenizer = AutoTokenizer.from_pretrained(
            model_name,
            cache_dir="/models",
            src_lang="zho_Hans"  # é»˜è®¤æºè¯­è¨€ï¼šç®€ä½“ä¸­æ–‡
        )
        
        self.model = AutoModelForSeq2SeqLM.from_pretrained(
            model_name,
            torch_dtype=torch.float16,
            cache_dir="/models",
        ).to("cuda")
        
        # å¸¸ç”¨è¯­è¨€ä»£ç æ˜ å°„
        self.lang_codes = {
            "zh": "zho_Hans",      # ç®€ä½“ä¸­æ–‡
            "zh-tw": "zho_Hant",   # ç¹ä½“ä¸­æ–‡
            "en": "eng_Latn",      # è‹±è¯­
            "ja": "jpn_Jpan",      # æ—¥è¯­
            "ko": "kor_Hang",      # éŸ©è¯­
            "fr": "fra_Latn",      # æ³•è¯­
            "de": "deu_Latn",      # å¾·è¯­
            "es": "spa_Latn",      # è¥¿ç­ç‰™è¯­
            "ru": "rus_Cyrl",      # ä¿„è¯­
            "ar": "arb_Arab",      # é˜¿æ‹‰ä¼¯è¯­
            "pt": "por_Latn",      # è‘¡è„ç‰™è¯­
            "it": "ita_Latn",      # æ„å¤§åˆ©è¯­
            "th": "tha_Thai",      # æ³°è¯­
            "vi": "vie_Latn",      # è¶Šå—è¯­
            "id": "ind_Latn",      # å°å°¼è¯­
        }
        
        print("âœ“ NLLB æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @modal.method()
    def translate(
        self,
        text: str,
        source_lang: str = "zh",
        target_lang: str = "en",
        max_length: int = 512
    ) -> str:
        """
        ç¿»è¯‘æ–‡æœ¬
        
        Args:
            text: å¾…ç¿»è¯‘æ–‡æœ¬
            source_lang: æºè¯­è¨€ä»£ç ï¼ˆå¦‚ zh, en, jaï¼‰
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦
            
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        # è½¬æ¢è¯­è¨€ä»£ç 
        src_code = self.lang_codes.get(source_lang, source_lang)
        tgt_code = self.lang_codes.get(target_lang, target_lang)
        
        # è®¾ç½®æºè¯­è¨€
        self.tokenizer.src_lang = src_code
        
        # ç¼–ç è¾“å…¥
        inputs = self.tokenizer(
            text,
            return_tensors="pt",
            padding=True,
            truncation=True,
            max_length=512
        ).to("cuda")
        
        # ç”Ÿæˆç¿»è¯‘
        translated_tokens = self.model.generate(
            **inputs,
            forced_bos_token_id=self.tokenizer.lang_code_to_id[tgt_code],
            max_length=max_length,
            num_beams=5,  # ä½¿ç”¨ beam search æé«˜è´¨é‡
            early_stopping=True
        )
        
        # è§£ç è¾“å‡º
        translation = self.tokenizer.batch_decode(
            translated_tokens,
            skip_special_tokens=True
        )[0]
        
        return translation.strip()
    
    @modal.method()
    def batch_translate(
        self,
        texts: list[str],
        source_lang: str = "zh",
        target_lang: str = "en"
    ) -> list[str]:
        """
        æ‰¹é‡ç¿»è¯‘
        
        Args:
            texts: å¾…ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        results = []
        for text in texts:
            translation = self.translate(text, source_lang, target_lang)
            results.append(translation)
        return results


@app.function(image=image)
@modal.web_endpoint(method="POST")
def translate_api(data: dict):
    """
    ç¿»è¯‘ API ç«¯ç‚¹
    
    POST /translate_api
    {
        "text": "ä½ å¥½ï¼Œä¸–ç•Œï¼",
        "source_lang": "zh",
        "target_lang": "en"
    }
    
    æˆ–æ‰¹é‡ç¿»è¯‘ï¼š
    {
        "texts": ["ä½ å¥½", "ä¸–ç•Œ"],
        "source_lang": "zh",
        "target_lang": "en"
    }
    """
    translator = NLLBTranslator()
    
    # æ‰¹é‡ç¿»è¯‘
    if "texts" in data:
        translations = translator.batch_translate.remote(
            texts=data["texts"],
            source_lang=data.get("source_lang", "zh"),
            target_lang=data.get("target_lang", "en")
        )
        return {
            "translations": translations,
            "count": len(translations)
        }
    
    # å•æ¡ç¿»è¯‘
    translation = translator.translate.remote(
        text=data["text"],
        source_lang=data.get("source_lang", "zh"),
        target_lang=data.get("target_lang", "en")
    )
    
    return {
        "translation": translation,
        "source_lang": data.get("source_lang", "zh"),
        "target_lang": data.get("target_lang", "en")
    }


@app.local_entrypoint()
def main():
    """æµ‹è¯•ç¿»è¯‘åŠŸèƒ½"""
    translator = NLLBTranslator()
    
    print("\n=== NLLB ç¿»è¯‘æµ‹è¯• ===\n")
    
    # æµ‹è¯• 1: ä¸­è¯‘è‹±
    text_zh = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œï¼Œæœºå™¨å­¦ä¹ è®©è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ ã€‚"
    result_en = translator.translate.remote(text_zh, "zh", "en")
    print(f"ä¸­æ–‡: {text_zh}")
    print(f"è‹±æ–‡: {result_en}\n")
    
    # æµ‹è¯• 2: è‹±è¯‘æ—¥
    text_en = "Machine learning is a subset of artificial intelligence."
    result_ja = translator.translate.remote(text_en, "en", "ja")
    print(f"English: {text_en}")
    print(f"æ—¥æœ¬èª: {result_ja}\n")
    
    # æµ‹è¯• 3: ä¸­è¯‘æ³•
    text_zh2 = "ä»Šå¤©å¤©æ°”å¾ˆå¥½ã€‚"
    result_fr = translator.translate.remote(text_zh2, "zh", "fr")
    print(f"ä¸­æ–‡: {text_zh2}")
    print(f"FranÃ§ais: {result_fr}\n")
    
    # æµ‹è¯• 4: æ‰¹é‡ç¿»è¯‘
    texts = [
        "ä½ å¥½",
        "è°¢è°¢",
        "å†è§"
    ]
    results = translator.batch_translate.remote(texts, "zh", "en")
    print("æ‰¹é‡ç¿»è¯‘:")
    for zh, en in zip(texts, results):
        print(f"  {zh} -> {en}")
    
    print("\nâœ“ æµ‹è¯•å®Œæˆ")
