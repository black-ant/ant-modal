"""
LoRA å¾®è°ƒè®­ç»ƒæœåŠ¡
ä½¿ç”¨ LoRA æŠ€æœ¯å¾®è°ƒ Stable Diffusion æ¨¡å‹
"""
import modal

app = modal.App("lora-training")

# æ„å»ºé•œåƒ
image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "diffusers==0.24.0",
        "transformers==4.36.0",
        "accelerate",
        "peft",  # LoRA åº“
        "torch==2.1.0",
        "torchvision",
        "datasets",
        "pillow",
    )
)

# æ•°æ®å’Œæ¨¡å‹å­˜å‚¨
training_volume = modal.Volume.from_name("lora-training", create_if_missing=True)


@app.function(
    image=image,
    gpu="A100",
    volumes={"/training": training_volume},
    timeout=3600,  # 1å°æ—¶
)
def train_lora(
    base_model: str = "stabilityai/stable-diffusion-xl-base-1.0",
    training_images_dir: str = "/training/images",
    output_dir: str = "/training/output",
    prompt: str = "a photo of sks person",
    num_train_epochs: int = 100,
    learning_rate: float = 1e-4,
    rank: int = 4,
):
    """
    è®­ç»ƒ LoRA æ¨¡å‹
    
    Args:
        base_model: åŸºç¡€æ¨¡å‹
        training_images_dir: è®­ç»ƒå›¾ç‰‡ç›®å½•
        output_dir: è¾“å‡ºç›®å½•
        prompt: è®­ç»ƒæç¤ºè¯
        num_train_epochs: è®­ç»ƒè½®æ•°
        learning_rate: å­¦ä¹ ç‡
        rank: LoRA rank
    """
    from diffusers import StableDiffusionXLPipeline
    from peft import LoraConfig, get_peft_model
    import torch
    from torch.utils.data import Dataset, DataLoader
    from PIL import Image
    import os
    
    print("ğŸ¨ å¼€å§‹ LoRA è®­ç»ƒ...")
    
    # åŠ è½½åŸºç¡€æ¨¡å‹
    print("åŠ è½½åŸºç¡€æ¨¡å‹...")
    pipe = StableDiffusionXLPipeline.from_pretrained(
        base_model,
        torch_dtype=torch.float16
    )
    pipe.to("cuda")
    
    # é…ç½® LoRA
    lora_config = LoraConfig(
        r=rank,
        lora_alpha=rank,
        target_modules=["to_q", "to_v"],
        lora_dropout=0.1,
    )
    
    # åº”ç”¨ LoRA
    unet = get_peft_model(pipe.unet, lora_config)
    
    # å‡†å¤‡æ•°æ®é›†
    class ImageDataset(Dataset):
        def __init__(self, image_dir):
            self.images = [
                os.path.join(image_dir, f)
                for f in os.listdir(image_dir)
                if f.endswith(('.png', '.jpg', '.jpeg'))
            ]
        
        def __len__(self):
            return len(self.images)
        
        def __getitem__(self, idx):
            image = Image.open(self.images[idx]).convert("RGB")
            return image
    
    dataset = ImageDataset(training_images_dir)
    dataloader = DataLoader(dataset, batch_size=1, shuffle=True)
    
    # è®­ç»ƒå¾ªç¯
    optimizer = torch.optim.AdamW(unet.parameters(), lr=learning_rate)
    
    print(f"å¼€å§‹è®­ç»ƒ {num_train_epochs} è½®...")
    for epoch in range(num_train_epochs):
        for batch_idx, images in enumerate(dataloader):
            # è®­ç»ƒæ­¥éª¤
            # ... (ç®€åŒ–ç¤ºä¾‹)
            pass
        
        if (epoch + 1) % 10 == 0:
            print(f"Epoch {epoch + 1}/{num_train_epochs}")
    
    # ä¿å­˜ LoRA æƒé‡
    os.makedirs(output_dir, exist_ok=True)
    unet.save_pretrained(output_dir)
    
    # æäº¤åˆ° Volume
    training_volume.commit()
    
    print(f"âœ“ LoRA è®­ç»ƒå®Œæˆï¼Œæƒé‡å·²ä¿å­˜åˆ° {output_dir}")
    return {"status": "completed", "output_dir": output_dir}


@app.function(
    image=image,
    gpu="A10G",
    volumes={"/training": training_volume},
)
def generate_with_lora(
    prompt: str,
    lora_path: str = "/training/output",
    base_model: str = "stabilityai/stable-diffusion-xl-base-1.0"
) -> bytes:
    """
    ä½¿ç”¨è®­ç»ƒå¥½çš„ LoRA ç”Ÿæˆå›¾åƒ
    """
    from diffusers import StableDiffusionXLPipeline
    import torch
    import io
    
    print("ğŸ¨ ä½¿ç”¨ LoRA ç”Ÿæˆå›¾åƒ...")
    
    pipe = StableDiffusionXLPipeline.from_pretrained(
        base_model,
        torch_dtype=torch.float16
    )
    pipe.load_lora_weights(lora_path)
    pipe.to("cuda")
    
    image = pipe(prompt).images[0]
    
    buf = io.BytesIO()
    image.save(buf, format="PNG")
    
    print("âœ“ å›¾åƒç”Ÿæˆå®Œæˆ")
    return buf.getvalue()


@app.local_entrypoint()
def main(action: str = "train"):
    """
    æœ¬åœ°å…¥å£
    
    ä½¿ç”¨æ–¹æ³•:
    modal run lora_training.py --action=train
    modal run lora_training.py --action=generate
    """
    if action == "train":
        result = train_lora.remote()
        print(result)
    elif action == "generate":
        image_bytes = generate_with_lora.remote("a photo of sks person")
        with open("lora_output.png", "wb") as f:
            f.write(image_bytes)
        print("âœ“ å›¾åƒå·²ä¿å­˜")
