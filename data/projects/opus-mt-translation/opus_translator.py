"""
Opus-MT è½»é‡çº§ç¿»è¯‘æœåŠ¡
ä½¿ç”¨ Helsinki-NLP çš„ Opus-MT æ¨¡å‹è¿›è¡Œç¿»è¯‘

ä¼˜åŠ¿ï¼š
- æè½»é‡çº§ï¼Œæ¨¡å‹ä»… 300MB å·¦å³
- CPU å³å¯è¿è¡Œï¼Œæ— éœ€ GPUï¼ˆå¯é€‰ GPU åŠ é€Ÿï¼‰
- æ¨ç†é€Ÿåº¦æå¿«
- æˆæœ¬æä½

é€‚ç”¨åœºæ™¯ï¼š
- é¢„ç®—æœ‰é™çš„ç¿»è¯‘æœåŠ¡
- ç‰¹å®šè¯­è¨€å¯¹çš„é«˜é¢‘ç¿»è¯‘
- éœ€è¦æå¿«å“åº”çš„åœºæ™¯
"""
import modal

app = modal.App("opus-mt-translation")

# è½»é‡çº§é•œåƒ
image = (
    modal.Image.debian_slim(python_version="3.11")
    .pip_install(
        "transformers==4.36.0",
        "torch==2.1.0",
        "sentencepiece",
    )
)

model_volume = modal.Volume.from_name("opus-models", create_if_missing=True)


@app.cls(
    image=image,
    cpu=2.0,  # ä½¿ç”¨ CPUï¼Œæˆæœ¬æ›´ä½
    # gpu="T4",  # å¦‚éœ€æ›´å¿«é€Ÿåº¦å¯å¯ç”¨ GPU
    volumes={"/models": model_volume},
    timeout=600,
    container_idle_timeout=300,
)
class OpusMTTranslator:
    """Opus-MT ç¿»è¯‘æœåŠ¡ç±»"""
    
    @modal.enter()
    def load_models(self):
        """åŠ è½½å¸¸ç”¨è¯­è¨€å¯¹çš„æ¨¡å‹"""
        from transformers import MarianMTModel, MarianTokenizer
        
        print("ğŸš€ åŠ è½½ Opus-MT ç¿»è¯‘æ¨¡å‹...")
        
        # é¢„åŠ è½½å¸¸ç”¨è¯­è¨€å¯¹æ¨¡å‹
        self.models = {}
        self.tokenizers = {}
        
        # å®šä¹‰å¸¸ç”¨è¯­è¨€å¯¹
        language_pairs = [
            ("zh", "en"),  # ä¸­è¯‘è‹±
            ("en", "zh"),  # è‹±è¯‘ä¸­
            ("zh", "ja"),  # ä¸­è¯‘æ—¥
            ("ja", "zh"),  # æ—¥è¯‘ä¸­
            ("en", "ja"),  # è‹±è¯‘æ—¥
            ("ja", "en"),  # æ—¥è¯‘è‹±
        ]
        
        for src, tgt in language_pairs:
            model_name = f"Helsinki-NLP/opus-mt-{src}-{tgt}"
            try:
                print(f"  åŠ è½½ {src}->{tgt} æ¨¡å‹...")
                tokenizer = MarianTokenizer.from_pretrained(
                    model_name,
                    cache_dir="/models"
                )
                model = MarianMTModel.from_pretrained(
                    model_name,
                    cache_dir="/models"
                )
                
                # å¦‚æœä½¿ç”¨ GPUï¼Œç§»åŠ¨åˆ° GPU
                # model = model.to("cuda")
                
                self.models[f"{src}-{tgt}"] = model
                self.tokenizers[f"{src}-{tgt}"] = tokenizer
                print(f"  âœ“ {src}->{tgt} åŠ è½½å®Œæˆ")
            except Exception as e:
                print(f"  âš  {src}->{tgt} åŠ è½½å¤±è´¥: {e}")
        
        print("âœ“ Opus-MT æ¨¡å‹åŠ è½½å®Œæˆ")
    
    @modal.method()
    def translate(
        self,
        text: str,
        source_lang: str = "zh",
        target_lang: str = "en"
    ) -> str:
        """
        ç¿»è¯‘æ–‡æœ¬
        
        Args:
            text: å¾…ç¿»è¯‘æ–‡æœ¬
            source_lang: æºè¯­è¨€ä»£ç ï¼ˆzh, en, ja ç­‰ï¼‰
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            ç¿»è¯‘åçš„æ–‡æœ¬
        """
        pair_key = f"{source_lang}-{target_lang}"
        
        if pair_key not in self.models:
            return f"é”™è¯¯: ä¸æ”¯æŒ {source_lang} -> {target_lang} ç¿»è¯‘å¯¹"
        
        tokenizer = self.tokenizers[pair_key]
        model = self.models[pair_key]
        
        # ç¼–ç 
        inputs = tokenizer(text, return_tensors="pt", padding=True)
        
        # å¦‚æœä½¿ç”¨ GPU
        # inputs = {k: v.to("cuda") for k, v in inputs.items()}
        
        # ç¿»è¯‘
        translated = model.generate(**inputs, max_length=512)
        
        # è§£ç 
        result = tokenizer.decode(translated[0], skip_special_tokens=True)
        
        return result.strip()
    
    @modal.method()
    def batch_translate(
        self,
        texts: list[str],
        source_lang: str = "zh",
        target_lang: str = "en"
    ) -> list[str]:
        """
        æ‰¹é‡ç¿»è¯‘ï¼ˆæ›´é«˜æ•ˆï¼‰
        
        Args:
            texts: å¾…ç¿»è¯‘æ–‡æœ¬åˆ—è¡¨
            source_lang: æºè¯­è¨€ä»£ç 
            target_lang: ç›®æ ‡è¯­è¨€ä»£ç 
            
        Returns:
            ç¿»è¯‘ç»“æœåˆ—è¡¨
        """
        pair_key = f"{source_lang}-{target_lang}"
        
        if pair_key not in self.models:
            return [f"é”™è¯¯: ä¸æ”¯æŒ {source_lang} -> {target_lang}"] * len(texts)
        
        tokenizer = self.tokenizers[pair_key]
        model = self.models[pair_key]
        
        # æ‰¹é‡ç¼–ç 
        inputs = tokenizer(texts, return_tensors="pt", padding=True, truncation=True)
        
        # æ‰¹é‡ç¿»è¯‘
        translated = model.generate(**inputs, max_length=512)
        
        # æ‰¹é‡è§£ç 
        results = [
            tokenizer.decode(t, skip_special_tokens=True)
            for t in translated
        ]
        
        return [r.strip() for r in results]
    
    @modal.method()
    def get_supported_pairs(self) -> list[str]:
        """è·å–æ”¯æŒçš„è¯­è¨€å¯¹åˆ—è¡¨"""
        return list(self.models.keys())


@app.function(image=image)
@modal.web_endpoint(method="POST")
def translate_api(data: dict):
    """
    ç¿»è¯‘ API ç«¯ç‚¹
    
    POST /translate_api
    {
        "text": "ä½ å¥½ï¼Œä¸–ç•Œï¼",
        "source_lang": "zh",
        "target_lang": "en"
    }
    """
    translator = OpusMTTranslator()
    
    # æ‰¹é‡ç¿»è¯‘
    if "texts" in data:
        translations = translator.batch_translate.remote(
            texts=data["texts"],
            source_lang=data.get("source_lang", "zh"),
            target_lang=data.get("target_lang", "en")
        )
        return {"translations": translations}
    
    # å•æ¡ç¿»è¯‘
    translation = translator.translate.remote(
        text=data["text"],
        source_lang=data.get("source_lang", "zh"),
        target_lang=data.get("target_lang", "en")
    )
    
    return {"translation": translation}


@app.function(image=image)
@modal.web_endpoint(method="GET")
def supported_languages():
    """è·å–æ”¯æŒçš„è¯­è¨€å¯¹"""
    translator = OpusMTTranslator()
    pairs = translator.get_supported_pairs.remote()
    return {"supported_pairs": pairs}


@app.local_entrypoint()
def main():
    """æµ‹è¯•ç¿»è¯‘åŠŸèƒ½"""
    translator = OpusMTTranslator()
    
    print("\n=== Opus-MT ç¿»è¯‘æµ‹è¯• ===\n")
    
    # æ˜¾ç¤ºæ”¯æŒçš„è¯­è¨€å¯¹
    pairs = translator.get_supported_pairs.remote()
    print(f"æ”¯æŒçš„è¯­è¨€å¯¹: {', '.join(pairs)}\n")
    
    # æµ‹è¯• 1: ä¸­è¯‘è‹±
    text_zh = "äººå·¥æ™ºèƒ½æ­£åœ¨æ”¹å˜ä¸–ç•Œã€‚"
    result_en = translator.translate.remote(text_zh, "zh", "en")
    print(f"ä¸­æ–‡: {text_zh}")
    print(f"è‹±æ–‡: {result_en}\n")
    
    # æµ‹è¯• 2: è‹±è¯‘ä¸­
    text_en = "Machine learning is amazing."
    result_zh = translator.translate.remote(text_en, "en", "zh")
    print(f"English: {text_en}")
    print(f"ä¸­æ–‡: {result_zh}\n")
    
    # æµ‹è¯• 3: æ‰¹é‡ç¿»è¯‘
    texts = [
        "ä½ å¥½",
        "è°¢è°¢",
        "å†è§",
        "æ—©ä¸Šå¥½"
    ]
    results = translator.batch_translate.remote(texts, "zh", "en")
    print("æ‰¹é‡ç¿»è¯‘:")
    for zh, en in zip(texts, results):
        print(f"  {zh} -> {en}")
    
    print("\nâœ“ æµ‹è¯•å®Œæˆ")
