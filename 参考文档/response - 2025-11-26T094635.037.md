

<think>

用户希望我提供更详细、更完善的 Modal CLI 使用示例，包含基本代码，并且内容要充实到至少3000字。我需要提供更详细的示例代码和说明。

让我系统地介绍 Modal CLI 的各种能力，并配上完整的代码示例。

</think>

# Modal CLI 完整使用指南

Modal CLI 是 Modal 云计算平台的命令行工具，提供了从开发到部署的完整工作流支持。下面我将详细介绍各项能力及其实际应用示例。

## 一、基础设置与认证

### 1.1 安装与初始化

```bash
# 安装 Modal
pip install modal

# 初始化配置，会打开浏览器进行认证
modal setup

# 查看当前配置
modal config show

# 设置特定的配置项
modal config set environment prod
```

### 1.2 令牌管理

```bash
# 创建新的令牌
modal token new --profile production

# 列出所有令牌
modal token list

# 设置当前使用的令牌
modal token set <token-id>
```

## 二、应用开发与部署

### 2.1 基础应用示例

创建一个简单的 Web API 应用 `app.py`：

```python
import modal

# 创建 Modal 应用
app = modal.App("my-web-api")

# 定义自定义镜像，安装依赖
image = modal.Image.debian_slim().pip_install(
    "fastapi",
    "uvicorn",
    "pydantic"
)

# 定义一个简单的函数
@app.function(image=image)
def square(x: int) -> int:
    """计算平方"""
    return x * x

# 定义 Web 端点
@app.function(image=image)
@modal.web_endpoint(method="GET")
def hello(name: str = "World"):
    """HTTP 端点示例"""
    return {"message": f"Hello, {name}!"}

# 定义定时任务
@app.function(
    image=image,
    schedule=modal.Period(hours=1)
)
def scheduled_task():
    """每小时执行一次"""
    print("Running scheduled task...")
    # 执行定时任务逻辑

# 本地入口点
@app.local_entrypoint()
def main():
    """本地运行入口"""
    result = square.remote(10)
    print(f"Square of 10 is: {result}")
```

**CLI 操作命令：**

```bash
# 本地运行（开发模式）
modal run app.py

# 部署到云端
modal deploy app.py

# 查看部署的应用
modal app list

# 查看特定应用详情
modal app show my-web-api

# 停止应用
modal app stop my-web-api
```

### 2.2 开发服务器（热重载）

```python
# web_app.py
import modal

app = modal.App("dev-server")
image = modal.Image.debian_slim().pip_install("fastapi")

@app.function(image=image)
@modal.asgi_app()
def fastapi_app():
    from fastapi import FastAPI
    
    web_app = FastAPI()
    
    @web_app.get("/")
    def read_root():
        return {"message": "Hello from Modal!"}
    
    @web_app.get("/items/{item_id}")
    def read_item(item_id: int, q: str = None):
        return {"item_id": item_id, "q": q}
    
    return web_app
```

**启动开发服务器：**

```bash
# 启动开发服务器，支持代码热重载
modal serve web_app.py

# 服务会运行在本地，自动重载代码变更
# 输出示例：
# ✓ Created objects.
# ✓ App deployed in 3.2s
# View at: https://username--dev-server-fastapi-app.modal.run
```

## 三、高级功能示例

### 3.1 GPU 加速计算

```python
# ml_inference.py
import modal

app = modal.App("ml-inference")

# 使用 GPU 和预装机器学习库的镜像
image = (
    modal.Image.debian_slim()
    .pip_install(
        "torch",
        "transformers",
        "accelerate"
    )
)

# 下载模型权重
def download_model():
    from transformers import AutoModelForCausalLM, AutoTokenizer
    
    model_name = "gpt2"
    AutoModelForCausalLM.from_pretrained(model_name)
    AutoTokenizer.from_pretrained(model_name)

# 定义 GPU 函数
@app.function(
    image=image,
    gpu="T4",  # 使用 T4 GPU
    timeout=300,
    memory=2048
)
def generate_text(prompt: str, max_length: int = 50):
    """使用 GPT-2 生成文本"""
    from transformers import AutoModelForCausalLM, AutoTokenizer
    import torch
    
    model_name = "gpt2"
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForCausalLM.from_pretrained(model_name)
    
    # 移到 GPU
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model.to(device)
    
    inputs = tokenizer(prompt, return_tensors="pt").to(device)
    outputs = model.generate(
        **inputs,
        max_length=max_length,
        num_return_sequences=1
    )
    
    return tokenizer.decode(outputs[0], skip_special_tokens=True)

@app.local_entrypoint()
def main(prompt: str = "Once upon a time"):
    result = generate_text.remote(prompt)
    print(f"Generated: {result}")
```

**运行 GPU 任务：**

```bash
# 本地触发远程 GPU 执行
modal run ml_inference.py --prompt "The future of AI is"

# 部署为持久服务
modal deploy ml_inference.py
```

### 3.2 持久化存储（Volume）

```python
# data_processing.py
import modal

app = modal.App("data-processor")

# 创建持久化存储卷
volume = modal.Volume.from_name("my-data-volume", create_if_missing=True)

image = modal.Image.debian_slim().pip_install("pandas", "numpy")

@app.function(
    image=image,
    volumes={"/data": volume},
    timeout=600
)
def process_large_dataset(filename: str):
    """处理大型数据集并保存结果"""
    import pandas as pd
    import numpy as np
    
    # 从持久化存储读取
    df = pd.read_csv(f"/data/input/{filename}")
    
    # 数据处理
    df['processed'] = df['value'] * 2
    df['timestamp'] = pd.Timestamp.now()
    
    # 保存到持久化存储
    output_path = f"/data/output/processed_{filename}"
    df.to_csv(output_path, index=False)
    
    # 提交更改
    volume.commit()
    
    return {
        "rows_processed": len(df),
        "output_path": output_path
    }

@app.function(
    image=image,
    volumes={"/data": volume}
)
def list_files(directory: str = "/data"):
    """列出存储中的文件"""
    import os
    
    files = []
    for root, dirs, filenames in os.walk(directory):
        for filename in filenames:
            files.append(os.path.join(root, filename))
    
    return files

@app.local_entrypoint()
def main():
    # 列出所有文件
    files = list_files.remote()
    print(f"Files in volume: {files}")
```

**Volume 管理命令：**

```bash
# 列出所有 Volume
modal volume list

# 查看特定 Volume 详情
modal volume get my-data-volume

# 删除 Volume
modal volume delete my-data-volume

# 运行数据处理任务
modal run data_processing.py
```

### 3.3 密钥管理

```bash
# 创建密钥
modal secret create my-api-keys \
    API_KEY=sk-xxx \
    DATABASE_URL=postgresql://user:pass@host/db

# 列出所有密钥
modal secret list

# 查看密钥（不显示值）
modal secret get my-api-keys
```

**在代码中使用密钥：**

```python
# api_client.py
import modal

app = modal.App("api-client")

# 引用密钥
secrets = modal.Secret.from_name("my-api-keys")

image = modal.Image.debian_slim().pip_install("requests")

@app.function(
    image=image,
    secrets=[secrets]
)
def call_external_api(endpoint: str):
    """调用外部 API"""
    import os
    import requests
    
    api_key = os.environ["API_KEY"]
    
    response = requests.get(
        endpoint,
        headers={"Authorization": f"Bearer {api_key}"}
    )
    
    return response.json()

@app.local_entrypoint()
def main():
    result = call_external_api.remote("https://api.example.com/data")
    print(result)
```

## 四、调试与监控

### 4.1 日志查看

```bash
# 实时查看应用日志
modal app logs my-web-api

# 查看最近的日志（最近100条）
modal app logs my-web-api --lines 100

# 持续跟踪日志（类似 tail -f）
modal app logs my-web-api --follow

# 查看特定时间范围的日志
modal app logs my-web-api --since "2024-11-25 10:00:00"
```

### 4.2 交互式 Shell

```python
# debug_app.py
import modal

app = modal.App("debug-example")

image = modal.Image.debian_slim().pip_install(
    "pandas",
    "matplotlib",
    "scikit-learn"
)

@app.function(image=image)
def analyze_data():
    """数据分析函数"""
    import pandas as pd
    
    data = pd.DataFrame({
        'x': range(100),
        'y': [i**2 for i in range(100)]
    })
    
    return data.describe()
```

**使用交互式 Shell：**

```bash
# 进入带有应用环境的 shell
modal shell debug_app.py

# 在 shell 中可以交互式地测试函数
# Python 3.11.x (Modal) [GCC] on linux
# >>> from debug_app import analyze_data
# >>> result = analyze_data.remote()
# >>> print(result)
```

### 4.3 性能分析

```python
# profiling_example.py
import modal

app = modal.App("performance-test")

@app.function()
def slow_function(n: int):
    """模拟耗时操作"""
    import time
    
    total = 0
    for i in range(n):
        total += i
        time.sleep(0.001)
    
    return total

@app.local_entrypoint()
def main():
    # 运行多次以收集性能数据
    for i in range(10):
        result = slow_function.remote(1000)
        print(f"Run {i+1}: {result}")
```

```bash
# 启用性能分析
modal profile app.py

# 查看执行统计
modal app stats my-web-api

# 查看函数调用次数和延迟
modal app stats my-web-api --function square
```

## 五、批量处理与并行

### 5.1 并行映射

```python
# parallel_processing.py
import modal

app = modal.App("parallel-processor")

image = modal.Image.debian_slim().pip_install("requests", "beautifulsoup4")

@app.function(
    image=image,
    retries=3,
    timeout=30
)
def scrape_url(url: str):
    """爬取单个 URL"""
    import requests
    from bs4 import BeautifulSoup
    
    response = requests.get(url, timeout=10)
    soup = BeautifulSoup(response.content, 'html.parser')
    
    return {
        'url': url,
        'title': soup.find('title').text if soup.find('title') else None,
        'status': response.status_code
    }

@app.local_entrypoint()
def main():
    """并行处理多个 URL"""
    urls = [
        "https://example.com",
        "https://example.org",
        "https://example.net",
        # ... 更多 URL
    ]
    
    # 使用 map 并行处理
    results = list(scrape_url.map(urls))
    
    # 打印结果
    for result in results:
        print(f"{result['url']}: {result['title']}")
```

### 5.2 队列处理

```python
# queue_processor.py
import modal

app = modal.App("queue-processor")

@app.function()
def process_item(item: dict):
    """处理队列中的单个项目"""
    import time
    
    print(f"Processing item: {item['id']}")
    time.sleep(1)  # 模拟处理时间
    
    return {
        'id': item['id'],
        'processed': True,
        'result': item['value'] * 2
    }

@app.local_entrypoint()
def main():
    """生成任务队列并处理"""
    items = [{'id': i, 'value': i * 10} for i in range(50)]
    
    # 并行处理所有项目
    results = list(process_item.starmap(
        [(item,) for item in items]
    ))
    
    print(f"Processed {len(results)} items")
    print(f"Sample result: {results[0]}")
```

## 六、环境管理

```bash
# 创建不同的部署环境
modal environment create staging
modal environment create production

# 切换环境
modal environment use staging

# 查看当前环境
modal environment current

# 部署到特定环境
modal deploy app.py --env production

# 列出所有环境
modal environment list
```

## 七、镜像管理

```python
# custom_image.py
import modal

# 构建自定义镜像
image = (
    modal.Image.from_registry(
        "nvidia/cuda:11.8.0-base-ubuntu22.04"
    )
    .apt_install("git", "wget")
    .pip_install(
        "torch",
        "torchvision",
        "torchaudio"
    )
    .run_commands(
        "wget https://example.com/model.pth -O /model.pth"
    )
)

app = modal.App("custom-image-app", image=image)

@app.function()
def use_custom_environment():
    """使用自定义镜像环境"""
    import torch
    print(f"PyTorch version: {torch.__version__}")
    print(f"CUDA available: {torch.cuda.is_available()}")
```

```bash
# 查看镜像列表
modal image list

# 构建并缓存镜像
modal image build custom_image.py
```

## 八、实用技巧

### 8.1 本地测试远程函数

```bash
# 在本地 Python 环境中测试 Modal 函数
modal run app.py::main

# 传递参数
modal run app.py::main --arg1 value1 --arg2 value2
```

### 8.2 查看应用信息

```bash
# 获取应用的详细信息
modal app describe my-web-api

# 以 JSON 格式输出
modal app describe my-web-api --json

# 查看应用的成本估算
modal app costs my-web-api --period last-month
```

这套完整的 Modal CLI 指南涵盖了从基础配置到高级应用的各个方面，包括 GPU 计算、数据持久化、并行处理、环境管理等核心功能，可以满足大部分云计算和机器学习部署需求。